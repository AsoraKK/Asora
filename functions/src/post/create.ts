/**
 * ASORA - POST CREATION FUNCTION
 *
 * âœ… Requirements:
 * - Validate JWT and extract user context via getUserContext()
 * - Enforce tier-based daily post limits (Free: 10, Premium: 100, Enterprise: unlimited)
 * - Validate request body with Joi schema:
 *   - text: string, max moderationConfig.charLimits.post
 *   - mediaUrl: optional string (URI format)
 *
 * âœ… Moderation Pipeline:
 * - Load dynamic config via getModerationConfig()
 * - If content.length > aiDetectionThreshold, call hiveClient.moderateText()
 * - Use dynamic thresholds from moderationConfig.ts
 * - Evaluate HiveResult.decision: approve | warn | block
 * - If "block", return 403 with reason and moderation breakdown
 * - If "warn", allow creation but set visibility to "warned"
 * - If "approve", proceed with visibility "public"
 *
 * âœ… Storage in Cosmos DB "posts" collection:
 * ```typescript
 * {
 *   id: uuidv4(),
 *   text: string,
 *   mediaUrl?: string,
 *   userId: string,
 *   userEmail: string,
 *   createdAt: ISO string,
 *   updatedAt: ISO string,
 *   moderation: {
 *     aiScore: number,
 *     decision: "approve" | "warn" | "block",
 *     categories: Record<string, number>,
 *     triggeredRules: string[],
 *     processedAt: ISO string
 *   },
 *   visibility: "public" | "warned" | "blocked",
 *   stats: { likesCount: 0, commentsCount: 0, sharesCount: 0, flagsCount: 0 },
 *   isDeleted: false
 * }
 * ```
 *
 * âœ… Response Format:
 * - 201 Created with comprehensive post data
 * - Include moderation transparency info for user appeals
 * - Return structured error messages for blocked content
 *
 * ðŸ§  Copilot Context:
 * - Use imports: getUserContext, getModerationConfig, moderateText, getContainer
 * - Handle async/await properly for all database and API calls
 * - Implement comprehensive error handling with try/catch blocks
 * - Follow Azure Functions v4 TypeScript patterns
 */

/**
 * ASORA PLATFORM CONTEXT
 *
 * Social network prioritizing authentic, human-created content
 * Stack: Azure Functions + TypeScript + Cosmos DB + Hive AI
 *
 * USER TIERS:
 * - Free: 10 posts/day
 * - Premium: 100 posts/day
 * - Enterprise: Unlimited posting
 *
 * AI MODERATION THRESHOLDS:
 * - score < 0.3: âœ… Safe (immediate visibility)
 * - score 0.3â€“0.7: âš ï¸ Warn (visible with warning)
 * - score > 0.7: ðŸš« Block (reject content)
 *
 * COLLECTIONS: users, posts, comments, likes, feeds, flags, moderationLogs
 *
 * Write production-grade TypeScript with:
 * - JWT auth validation via shared utilities
 * - Comprehensive error handling (400/401/404/500)
 * - Input validation and sanitization
 * - Structured logging for monitoring
 * - Rate limiting and tier enforcement
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from '@azure/functions';
import { getUserContext } from '../shared/auth';
import { getContainer } from '../shared/cosmosClient';
import { CHARACTER_LIMITS } from '../shared/policy';
import { getModerationConfig, getDynamicContentVisibility } from '../shared/moderationConfig';
import { moderateText } from '../shared/hiveClient';
import { hashEmail, createPrivacySafeUserId, privacyLog } from '../shared/privacyUtils';
import { validateAttachmentCount, getDailyPostLimit, UserTier } from '../shared/tierLimits';
import { v4 as uuidv4 } from 'uuid';
import Joi from 'joi';

export async function postCreate(
  request: HttpRequest,
  context: InvocationContext
): Promise<HttpResponseInit> {
  try {
    // 1. Load dynamic moderation configuration
    const moderationConfig = await getModerationConfig();

    // 2. Validate JWT and extract user context
    const userContext = getUserContext(request);
    if (!userContext) {
      return {
        status: 401,
        jsonBody: { error: 'Unauthorized - Invalid or missing JWT token' },
      };
    }

    // 3. Validate input using Joi with dynamic policy limits
    const schema = Joi.object({
      text: Joi.string().max(moderationConfig.charLimits.post).required(),
      mediaUrl: Joi.string().uri().optional(),
      attachments: Joi.array()
        .items(
          Joi.object({
            url: Joi.string().uri().required(),
            type: Joi.string().valid('image', 'video', 'document').required(),
            size: Joi.number().positive().optional(),
          })
        )
        .optional(),
    });

    const { error, value } = schema.validate(await request.json());
    if (error) {
      return {
        status: 400,
        jsonBody: { error: `Validation failed: ${error.message}` },
      };
    }

    // 4. Validate tier-based attachment limits
    const userTier = (userContext.tier || 'Free') as UserTier;
    const attachments = value.attachments || [];
    const attachmentValidation = validateAttachmentCount(userTier, attachments.length);

    if (!attachmentValidation.valid) {
      return {
        status: 403,
        jsonBody: {
          error: 'Tier media limit exceeded',
          code: 'TIER_MEDIA_LIMIT',
          allowed: attachmentValidation.allowed,
          attempted: attachments.length,
          tier: userTier,
        },
      };
    }

    // 5. Check tier-based posting limits
    // Check user's daily post count against tier limits
    const dailyLimit = getDailyPostLimit(userTier);

    if (dailyLimit !== Infinity) {
      // For now, we'll implement a simple check. In production, this would query the database
      // for posts created today by this user
      // SECURITY: Use privacy-safe logging instead of exposing email
      const logData = privacyLog(`ðŸ“Š User daily limit check completed`, userContext.email, {
        dailyLimit,
        userTier,
      });
      console.log(logData);
      // TODO: Implement actual database query for daily post count
    }

    // 5. Send content to Hive AI for moderation using enhanced client
    let hiveResult;
    try {
      hiveResult = await moderateText({
        content: value.text,
        userId: userContext.userId,
        contextType: 'post',
      });

      context.log(
        `Hive AI analysis: score=${hiveResult.score}, decision=${hiveResult.decision}, categories=${Object.keys(hiveResult.categories).join(',')}`
      );

      if (hiveResult.triggeredRules.length > 0) {
        context.log(`Triggered rules: ${hiveResult.triggeredRules.join('; ')}`);
      }
    } catch (hiveError: any) {
      context.warn(`Hive AI request failed: ${hiveError.message}`);
      // Fallback to safe defaults
      hiveResult = {
        score: 0.0,
        categories: {},
        decision: 'approve' as const,
        triggeredRules: ['API_FALLBACK'],
        raw: {},
      };
    }

    // 6. Apply dynamic AI moderation decision
    if (hiveResult.decision === 'block') {
      context.log(`Content blocked - Decision: ${hiveResult.decision}, Score: ${hiveResult.score}`);
      return {
        status: 403,
        jsonBody: {
          error: 'Content rejected due to AI moderation',
          reason: 'Content appears to violate community guidelines',
          details: {
            score: hiveResult.score,
            triggeredRules: hiveResult.triggeredRules,
            categories: hiveResult.categories,
          },
        },
      };
    }

    // 7. Store post in Cosmos DB with enhanced moderation data
    const postsContainer = getContainer('posts');
    const postId = uuidv4();
    const createdAt = new Date().toISOString();

    const post = {
      id: postId,
      text: value.text,
      mediaUrl: value.mediaUrl || null,
      attachments: attachments,
      userId: userContext.userId,
      userHashedId: hashEmail(userContext.email), // SECURITY: Hash email for privacy
      createdAt,
      updatedAt: createdAt,
      moderation: {
        aiScore: hiveResult.score,
        decision: hiveResult.decision,
        categories: hiveResult.categories,
        triggeredRules: hiveResult.triggeredRules,
        processedAt: createdAt,
      },
      visibility: await getDynamicContentVisibility(hiveResult.score),
      stats: {
        likesCount: 0,
        commentsCount: 0,
        sharesCount: 0,
        flagsCount: 0,
      },
      isDeleted: false,
    };

    await postsContainer.items.create(post);

    context.log(`âœ… Post created successfully: ${postId} by user ${userContext.userId}`);

    // 8. Return success response with enhanced moderation data
    const getAiStatus = (score: number): string => {
      if (score < moderationConfig.thresholds.safe) return 'safe';
      if (score < moderationConfig.thresholds.warned) return 'warned';
      return 'blocked';
    };

    // 9. Return success response
    return {
      status: 201,
      jsonBody: {
        success: true,
        postId,
        post: {
          id: post.id,
          text: post.text,
          mediaUrl: post.mediaUrl,
          createdAt: post.createdAt,
          visibility: post.visibility,
          moderation: {
            score: hiveResult.score,
            status: getAiStatus(hiveResult.score),
            decision: hiveResult.decision,
            categories: hiveResult.categories,
            triggeredRules: hiveResult.triggeredRules,
          },
        },
      },
    };
  } catch (error: any) {
    context.error('Post creation error:', error);
    return {
      status: 500,
      jsonBody: {
        error: 'Internal server error',
        message:
          process.env['NODE_ENV'] === 'development' ? error.message : 'Unable to create post',
      },
    };
  }
}

app.http('postCreate', {
  methods: ['POST'],
  authLevel: 'anonymous',
  route: 'post/create',
  handler: postCreate,
});
